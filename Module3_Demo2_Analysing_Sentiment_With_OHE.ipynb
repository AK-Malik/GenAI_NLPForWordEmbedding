{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AK-Malik/GenAI_NLPForWordEmbedding/blob/main/Module3_Demo2_Analysing_Sentiment_With_OHE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysing Sentiment"
      ],
      "metadata": {
        "id": "QlJeKdJfTPMp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's first import everything and load the dataset"
      ],
      "metadata": {
        "id": "epE01e6NbbMg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ri00gAaqSzrq",
        "outputId": "fa1bef20-4d5b-4405-b426-5ccfb882038d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from textblob import TextBlob, Word\n",
        "import nltk\n",
        "import torch\n",
        "from torch import nn\n",
        "import seaborn as sns\n",
        "nltk.download('punkt')\n",
        "\n",
        "%matplotlib inline\n",
        "sns.set(rc={'figure.figsize':(20,20)})\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile get_data.sh\n",
        "if [ ! -f yelp.csv ]; then\n",
        "  wget https://raw.githubusercontent.com/axel-sirota/implement-nlp-word-embedding/main/module3/data/yelp.csv\n",
        "fi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHuUsDMlTXhM",
        "outputId": "1567b87a-1640-434f-81f6-58c537b5f378"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing get_data.sh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash get_data.sh\n"
      ],
      "metadata": {
        "id": "Uq4-oO3KTnbQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b45f477c-1d5d-4f29-a06c-c012ee276272"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-02 06:04:04--  https://raw.githubusercontent.com/axel-sirota/implement-nlp-word-embedding/main/module3/data/yelp.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8091185 (7.7M) [text/plain]\n",
            "Saving to: ‘yelp.csv’\n",
            "\n",
            "yelp.csv            100%[===================>]   7.72M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2025-05-02 06:04:04 (106 MB/s) - ‘yelp.csv’ saved [8091185/8091185]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = './yelp.csv'\n",
        "yelp = pd.read_csv(path)\n",
        "# Create a new DataFrame that only contains the 5-star and 1-star reviews.\n",
        "yelp_best_worst = yelp[(yelp.stars==5) | (yelp.stars==1)]\n",
        "\n",
        "# Define X and y.\n",
        "X = yelp_best_worst.text\n",
        "y = yelp_best_worst.stars.map({1:0, 5:1})\n"
      ],
      "metadata": {
        "id": "i32aK_G6TZl9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Doing the train_test split and defining model"
      ],
      "metadata": {
        "id": "quWimVZjbemw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)"
      ],
      "metadata": {
        "id": "gPK5YmDMTbby"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vect = CountVectorizer()\n",
        "X_train_dtm = vect.fit_transform(X_train)\n",
        "X_test_dtm = vect.transform(X_test)"
      ],
      "metadata": {
        "id": "v0LSrnpiUs8p"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor = torch.Tensor(X_train_dtm.toarray()).to(device)\n",
        "X_test_tensor = torch.Tensor(X_test_dtm.toarray()).to(device)\n",
        "y_train = torch.Tensor(y_train.values).type(torch.LongTensor).to(device)\n",
        "y_test = torch.Tensor(y_test.values).type(torch.LongTensor).to(device)"
      ],
      "metadata": {
        "id": "SwdtffgTVRM0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "  nn.Linear(X_train_tensor.shape[1], 2),\n",
        "  nn.LogSoftmax(dim = 1)\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "Ip1U599PVXrg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(X):\n",
        "  return model(X).to(device)\n",
        "\n",
        "def loss(y_pred, y):\n",
        "  return nn.functional.nll_loss(y_pred, y)\n",
        "\n",
        "def metric(y_pred, y):  # -> accuracy\n",
        "  return (1 / len(y)) * ((y_pred.argmax(dim = 1) == y).sum())\n"
      ],
      "metadata": {
        "id": "RB_PGA_7WTC5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's verify the metric makes sense"
      ],
      "metadata": {
        "id": "KMQJasS-YOpF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred = model(X_train_tensor).to(device)\n",
        "y_train_pred.argmax(dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbKjRHJyWbTU",
        "outputId": "4afc8af8-c606-4548-8529-7de04a5e6275"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 1,  ..., 1, 1, 1], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(y_train_pred.argmax(dim = 1) == y_train).sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qnE5Aj0WfoX",
        "outputId": "04fa8416-51b7-4a31-993f-6da57ec1741f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2303, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metric(y_train_pred, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMIbTz7mWm-v",
        "outputId": "1edfecc9-6d44-4b7d-9967-bed0dcfe6c27"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.7047, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del y_train_pred"
      ],
      "metadata": {
        "id": "JD4jGHO3YelM"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The training routine"
      ],
      "metadata": {
        "id": "ROXVUovhYRWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters())"
      ],
      "metadata": {
        "id": "U80Pu2e8X3Il"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1000\n",
        "for i in range(epochs):\n",
        "  y_pred = forward(X_train_tensor)\n",
        "  xe = loss(y_pred, y_train)\n",
        "  accuracy = metric(y_pred, y_train)\n",
        "  xe.backward()\n",
        "  if i % 100 == 0:\n",
        "    print(\"Loss: \", xe, \" Accuracy \", accuracy.data.item())\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kchBdsMYT94",
        "outputId": "d7162d56-3963-4938-bceb-e126cf8701ae"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:  tensor(0.6754, device='cuda:0', grad_fn=<NllLossBackward0>)  Accuracy  0.7047123908996582\n",
            "Loss:  tensor(0.1304, device='cuda:0', grad_fn=<NllLossBackward0>)  Accuracy  0.9917380809783936\n",
            "Loss:  tensor(0.0721, device='cuda:0', grad_fn=<NllLossBackward0>)  Accuracy  0.9951040744781494\n",
            "Loss:  tensor(0.0486, device='cuda:0', grad_fn=<NllLossBackward0>)  Accuracy  0.9966340661048889\n",
            "Loss:  tensor(0.0361, device='cuda:0', grad_fn=<NllLossBackward0>)  Accuracy  0.9972460269927979\n",
            "Loss:  tensor(0.0283, device='cuda:0', grad_fn=<NllLossBackward0>)  Accuracy  0.9972460269927979\n",
            "Loss:  tensor(0.0231, device='cuda:0', grad_fn=<NllLossBackward0>)  Accuracy  0.9981640577316284\n",
            "Loss:  tensor(0.0193, device='cuda:0', grad_fn=<NllLossBackward0>)  Accuracy  0.9984700083732605\n",
            "Loss:  tensor(0.0165, device='cuda:0', grad_fn=<NllLossBackward0>)  Accuracy  0.9987760186195374\n",
            "Loss:  tensor(0.0144, device='cuda:0', grad_fn=<NllLossBackward0>)  Accuracy  0.9987760186195374\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = forward(X_test_tensor)\n",
        "print(f'Model accuracy is {metric(y_test_pred, y_test)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlU4QbIPYrPc",
        "outputId": "f2f3ec02-178d-4085-ec9b-18b75d4f4688"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy is 0.898533046245575\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Some manual validation"
      ],
      "metadata": {
        "id": "tNqRJ0wCbXMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "review = np.array([\"This place was fantastic\"])\n",
        "vectorized_review = torch.Tensor(vect.transform(review).toarray()).to(device)"
      ],
      "metadata": {
        "id": "EgO7d2LdbYhD"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = forward(vectorized_review)\n",
        "prediction.argmax(dim = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icVOjVFybsU-",
        "outputId": "731219e4-ad21-4d38-94eb-6cad3f02d24a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Therefore, the model predicted correctly that the review was positive!"
      ],
      "metadata": {
        "id": "VBSc6m2LcPfk"
      }
    }
  ]
}